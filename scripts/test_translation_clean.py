#!/usr/bin/env python3
"""
æµ‹è¯•æ¸…æ´ç¿»è¯‘åŠŸèƒ½ - ç¡®ä¿æ²¡æœ‰ç¿»è¯‘è¯´æ˜
"""

import sys
import os

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ° sys.path
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

try:
    from dotenv import load_dotenv
    load_dotenv()
except ImportError:
    print("dotenv æ¨¡å—æœªå®‰è£…ï¼Œå°†ç›´æ¥ä½¿ç”¨ç¯å¢ƒå˜é‡")

from scripts.llm_provider import get_llm_provider

def test_clean_translation():
    """æµ‹è¯•æ¸…æ´ç¿»è¯‘åŠŸèƒ½"""
    
    # è·å–LLMæä¾›å•†
    llm = get_llm_provider()
    print(f"ä½¿ç”¨LLMæä¾›å•†: {type(llm).__name__}")
    
    # æµ‹è¯•æ–‡æœ¬ï¼ˆè¿™äº›æ˜¯å®¹æ˜“äº§ç”Ÿç¿»è¯‘è¯´æ˜çš„æ–‡æœ¬ï¼‰
    test_texts = [
        "A Website Builder for Everyone - Create stunning, high-performing websites in minutes without any code",
        "V-JEPA 2 - Meta's world model for physical understanding through video training",
        "Spill 2.0 - Visual conversations for culture-first social media with humor, insight, and authentic connection"
    ]
    
    print("\nğŸ§ª æµ‹è¯•æ¸…æ´ç¿»è¯‘åŠŸèƒ½...")
    print("=" * 60)
    
    for i, text in enumerate(test_texts, 1):
        print(f"\nğŸ“ æµ‹è¯•æ–‡æœ¬ {i}:")
        print(f"åŸæ–‡: {text}")
        print("-" * 40)
        
        try:
            # è°ƒç”¨ç¿»è¯‘
            translation = llm.translate_text(text)
            print(f"è¯‘æ–‡: {translation}")
            
            # æ£€æŸ¥æ˜¯å¦åŒ…å«ç¿»è¯‘è¯´æ˜
            problematic_phrases = [
                "ç¿»è¯‘è¯´æ˜", "æ³¨ï¼š", "è¯´æ˜ï¼š", "ï¼ˆç¿»è¯‘", "ï¼ˆè¯´æ˜", 
                "è¯‘è€…æ³¨", "æ³¨é‡Š", "è§£é‡Š", "ç¿»è¯‘æŠ€å·§", "å¤„ç†æ–¹å¼"
            ]
            
            has_explanation = any(phrase in translation for phrase in problematic_phrases)
            
            if has_explanation:
                print("âŒ æ£€æµ‹åˆ°ç¿»è¯‘è¯´æ˜ï¼")
                for phrase in problematic_phrases:
                    if phrase in translation:
                        print(f"   å‘ç°: '{phrase}'")
            else:
                print("âœ… ç¿»è¯‘å¹²å‡€ï¼Œæ— é¢å¤–è¯´æ˜")
                
        except Exception as e:
            print(f"âŒ ç¿»è¯‘å¤±è´¥: {e}")
        
        print("-" * 40)
    
    print(f"\nğŸ“Š æµ‹è¯•å®Œæˆï¼")

def test_with_different_providers():
    """æµ‹è¯•ä¸åŒçš„LLMæä¾›å•†"""
    providers = ["deepseek", "openai", "gemini", "openrouter"]
    
    test_text = "Revolutionary social experience with culture-first mindset"
    
    for provider_name in providers:
        print(f"\n{'='*50}")
        print(f"æµ‹è¯• {provider_name.upper()} æä¾›å•†")
        print(f"{'='*50}")
        
        # ä¸´æ—¶è®¾ç½®ç¯å¢ƒå˜é‡
        original_provider = os.getenv("LLM_PROVIDER")
        os.environ["LLM_PROVIDER"] = provider_name
        
        try:
            llm = get_llm_provider()
            translation = llm.translate_text(test_text)
            
            print(f"åŸæ–‡: {test_text}")
            print(f"è¯‘æ–‡: {translation}")
            
            # æ£€æŸ¥æ¸…æ´åº¦
            problematic_phrases = ["ç¿»è¯‘è¯´æ˜", "æ³¨ï¼š", "è¯´æ˜ï¼š", "ï¼ˆç¿»è¯‘", "ï¼ˆè¯´æ˜"]
            has_explanation = any(phrase in translation for phrase in problematic_phrases)
            
            if has_explanation:
                print("âŒ åŒ…å«ç¿»è¯‘è¯´æ˜")
            else:
                print("âœ… ç¿»è¯‘å¹²å‡€")
                
        except Exception as e:
            print(f"âŒ {provider_name} æä¾›å•†æµ‹è¯•å¤±è´¥: {e}")
        
        # æ¢å¤åŸå§‹ç¯å¢ƒå˜é‡
        if original_provider:
            os.environ["LLM_PROVIDER"] = original_provider
        elif "LLM_PROVIDER" in os.environ:
            del os.environ["LLM_PROVIDER"]

if __name__ == "__main__":
    import argparse
    
    parser = argparse.ArgumentParser(description="æµ‹è¯•æ¸…æ´ç¿»è¯‘åŠŸèƒ½")
    parser.add_argument("--all", action="store_true", help="æµ‹è¯•æ‰€æœ‰æä¾›å•†")
    
    args = parser.parse_args()
    
    if args.all:
        test_with_different_providers()
    else:
        test_clean_translation()
