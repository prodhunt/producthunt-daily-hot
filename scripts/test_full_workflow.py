import os
import sys
import json
import requests
from datetime import datetime, timedelta, timezone
import pytz
from requests.adapters import HTTPAdapter
from urllib3.util.retry import Retry

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ° sys.path
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

try:
    from dotenv import load_dotenv
    load_dotenv()
except ImportError:
    print("dotenv æ¨¡å—æœªå®‰è£…ï¼Œå°†ç›´æ¥ä½¿ç”¨ç¯å¢ƒå˜é‡")

# å¯¼å…¥LLMæä¾›å•†
from scripts.llm_provider import get_llm_provider

class Product:
    def __init__(self, id: str, name: str, tagline: str, description: str, votesCount: int, createdAt: str, featuredAt: str, website: str, url: str, media=None, **kwargs):
        self.name = name
        self.tagline = tagline
        self.description = description
        self.votes_count = votesCount
        self.created_at = self.convert_to_beijing_time(createdAt)
        self.featured = "æ˜¯" if featuredAt else "å¦"
        self.website = website
        self.url = url
        self.og_image_url = self.get_image_url_from_media(media)
        
        # åˆå§‹åŒ–æ—¶ä¸è°ƒç”¨LLMï¼Œä»¥ä¾¿æµ‹è¯•
        self.keyword = ""
        self.translated_tagline = ""
        self.translated_description = ""

    def get_image_url_from_media(self, media):
        try:
            if media and isinstance(media, list) and len(media) > 0:
                image_url = media[0].get('url', '')
                if image_url:
                    print(f"æˆåŠŸä»APIè·å–å›¾ç‰‡URL: {self.name}")
                    return image_url
            print(f"APIæœªè¿”å›å›¾ç‰‡ï¼Œå°è¯•ä½¿ç”¨å¤‡ç”¨æ–¹æ³•: {self.name}")
            return ""
        except Exception as e:
            print(f"è·å–å›¾ç‰‡URLæ—¶å‡ºé”™: {self.name}, é”™è¯¯: {e}")
            return ""

    def convert_to_beijing_time(self, utc_time_str: str) -> str:
        utc_time = datetime.strptime(utc_time_str, '%Y-%m-%dT%H:%M:%SZ')
        beijing_tz = pytz.timezone('Asia/Shanghai')
        beijing_time = utc_time.replace(tzinfo=pytz.utc).astimezone(beijing_tz)
        return beijing_time.strftime('%Yå¹´%mæœˆ%dæ—¥ %p%I:%M (åŒ—äº¬æ—¶é—´)')

    def to_markdown(self, rank: int) -> str:
        og_image_markdown = f"![{self.name}]({self.og_image_url})" if self.og_image_url else f"*å›¾ç‰‡æœªè·å–*"
        return (
            f"## [{rank}. {self.name}]({self.url})\n"
            f"**æ ‡è¯­**ï¼š{self.tagline if not self.translated_tagline else self.translated_tagline}\n"
            f"**ä»‹ç»**ï¼š{self.description if not self.translated_description else self.translated_description}\n"
            f"**äº§å“ç½‘ç«™**: [ç«‹å³è®¿é—®]({self.website})\n"
            f"**Product Hunt**: [View on Product Hunt]({self.url})\n\n"
            f"{og_image_markdown}\n\n"
            f"**å…³é”®è¯**ï¼š{self.keyword}\n"
            f"**ç¥¨æ•°**: ğŸ”º{self.votes_count}\n"
            f"**æ˜¯å¦ç²¾é€‰**ï¼š{self.featured}\n"
            f"**å‘å¸ƒæ—¶é—´**ï¼š{self.created_at}\n\n"
            f"---\n\n"
        )

def get_producthunt_token():
    """è·å–Product Hunt APIè®¿é—®ä»¤ç‰Œ"""
    developer_token = os.getenv('PRODUCTHUNT_DEVELOPER_TOKEN')
    if not developer_token:
        raise Exception("PRODUCTHUNT_DEVELOPER_TOKEN not found in environment variables")
    print(f"æˆåŠŸè·å–PRODUCTHUNT_DEVELOPER_TOKEN: {developer_token[:5]}...{developer_token[-5:]}")
    return developer_token

def fetch_product_hunt_data(date_str=None):
    """ä»Product Hunt APIè·å–æ•°æ®"""
    token = get_producthunt_token()
    
    if date_str is None:
        yesterday = datetime.now(timezone.utc) - timedelta(days=1)
        date_str = yesterday.strftime('%Y-%m-%d')
    
    print(f"è·å– {date_str} çš„æ•°æ®")
    
    url = "https://api.producthunt.com/v2/api/graphql"
    headers = {
        "Accept": "application/json",
        "Content-Type": "application/json",
        "Authorization": f"Bearer {token}",
        "User-Agent": "TestScript/1.0 (Testing API Connection)",
    }
    
    # è®¾ç½®é‡è¯•ç­–ç•¥
    retry_strategy = Retry(
        total=3,
        backoff_factor=1,
        status_forcelist=[429, 500, 502, 503, 504]
    )
    adapter = HTTPAdapter(max_retries=retry_strategy)
    session = requests.Session()
    session.mount("https://", adapter)
    
    # GraphQLæŸ¥è¯¢
    base_query = """
    {
      posts(order: VOTES, postedAfter: "%sT00:00:00Z", postedBefore: "%sT23:59:59Z", after: "%s") {
        nodes {
          id
          name
          tagline
          description
          votesCount
          createdAt
          featuredAt
          website
          url
          media {
            url
            type
            videoUrl
          }
        }
        pageInfo {
          hasNextPage
          endCursor
        }
      }
    }
    """
    
    all_posts = []
    has_next_page = True
    cursor = ""
    max_products = 5  # é™åˆ¶æµ‹è¯•æ—¶è·å–çš„äº§å“æ•°é‡
    
    try:
        while has_next_page and len(all_posts) < max_products:
            query = base_query % (date_str, date_str, cursor)
            print(f"å‘é€APIè¯·æ±‚ (å·²è·å– {len(all_posts)} ä¸ªäº§å“)...")
            response = session.post(url, headers=headers, json={"query": query})
            response.raise_for_status()
            
            data = response.json()
            if 'errors' in data:
                print(f"APIè¿”å›é”™è¯¯: {data['errors']}")
                break
                
            posts = data['data']['posts']['nodes']
            all_posts.extend(posts)
            
            page_info = data['data']['posts']['pageInfo']
            has_next_page = page_info['hasNextPage'] and len(all_posts) < max_products
            cursor = page_info['endCursor']
        
        print(f"æˆåŠŸè·å– {len(all_posts)} ä¸ªäº§å“æ•°æ®")
        
        # å°†åŸå§‹æ•°æ®ä¿å­˜åˆ°æ–‡ä»¶
        with open('product_hunt_raw_data.json', 'w', encoding='utf-8') as f:
            json.dump(all_posts, f, ensure_ascii=False, indent=2)
        print("åŸå§‹æ•°æ®å·²ä¿å­˜åˆ° product_hunt_raw_data.json æ–‡ä»¶")
        
        # è½¬æ¢ä¸ºProductå¯¹è±¡
        products = [Product(**post) for post in sorted(all_posts, key=lambda x: x['votesCount'], reverse=True)]
        return products
    except Exception as e:
        print(f"è·å–æ•°æ®å¤±è´¥: {e}")
        return []

def test_llm_integration(products, test_single=True):
    """æµ‹è¯•LLMé›†æˆ"""
    if not products:
        print("æ²¡æœ‰äº§å“æ•°æ®ï¼Œè·³è¿‡LLMæµ‹è¯•")
        return False
    
    try:
        llm = get_llm_provider()
        print(f"æˆåŠŸåˆå§‹åŒ–LLMæä¾›å•†: {llm.__class__.__name__}")
        
        if test_single:
            # åªæµ‹è¯•ç¬¬ä¸€ä¸ªäº§å“
            product = products[0]
            print(f"\næµ‹è¯•äº§å“ '{product.name}' çš„LLMåŠŸèƒ½:")
            
            print("æµ‹è¯•å…³é”®è¯ç”Ÿæˆ...")
            product.keyword = llm.generate_keywords(product.name, product.tagline, product.description)
            print(f"ç”Ÿæˆçš„å…³é”®è¯: {product.keyword}")
            
            print("æµ‹è¯•æ ‡è¯­ç¿»è¯‘...")
            product.translated_tagline = llm.translate_text(product.tagline)
            print(f"ç¿»è¯‘åçš„æ ‡è¯­: {product.translated_tagline}")
            
            print("æµ‹è¯•ç®€çŸ­æè¿°ç¿»è¯‘...")
            # åªç¿»è¯‘æè¿°çš„å‰100ä¸ªå­—ç¬¦ä½œä¸ºæµ‹è¯•
            short_desc = product.description[:100] + ("..." if len(product.description) > 100 else "")
            product.translated_description = llm.translate_text(short_desc)
            print(f"ç¿»è¯‘åçš„æè¿°: {product.translated_description}")
            
            return True
    except Exception as e:
        print(f"LLMæµ‹è¯•å¤±è´¥: {e}")
        return False

def generate_test_markdown(products, date_str=None):
    """ç”Ÿæˆæµ‹è¯•ç”¨çš„Markdownæ–‡ä»¶"""
    if not products:
        print("æ²¡æœ‰äº§å“æ•°æ®ï¼Œæ— æ³•ç”ŸæˆMarkdown")
        return False
    
    if date_str is None:
        today = datetime.now(timezone.utc)
        date_str = today.strftime('%Y-%m-%d')
    
    try:
        markdown_content = f"# PHä»Šæ—¥çƒ­æ¦œæµ‹è¯• | {date_str}\n\n"
        for rank, product in enumerate(products, 1):
            markdown_content += product.to_markdown(rank)
        
        os.makedirs('data', exist_ok=True)
        file_name = f"data/producthunt-test-{date_str}.md"
        with open(file_name, 'w', encoding='utf-8') as file:
            file.write(markdown_content)
        print(f"æµ‹è¯•æ–‡ä»¶ {file_name} ç”ŸæˆæˆåŠŸã€‚")
        return True
    except Exception as e:
        print(f"ç”ŸæˆMarkdownæ–‡ä»¶å¤±è´¥: {e}")
        return False

def main():
    print("=== å¼€å§‹æµ‹è¯• Product Hunt å®Œæ•´å·¥ä½œæµ ===")
    
    # æ­¥éª¤1: æµ‹è¯•APIè¿æ¥å’Œæ•°æ®è·å–
    print("\n[æ­¥éª¤1] æµ‹è¯•APIè¿æ¥å’Œæ•°æ®è·å–")
    products = fetch_product_hunt_data()
    if not products:
        print("âŒ æ­¥éª¤1å¤±è´¥: æ— æ³•è·å–äº§å“æ•°æ®")
        return
    print("âœ… æ­¥éª¤1æˆåŠŸ: æˆåŠŸè·å–äº§å“æ•°æ®")
    
    # æ­¥éª¤2: æµ‹è¯•LLMé›†æˆ
    print("\n[æ­¥éª¤2] æµ‹è¯•LLMé›†æˆ")
    llm_success = test_llm_integration(products)
    if not llm_success:
        print("âŒ æ­¥éª¤2å¤±è´¥: LLMé›†æˆæµ‹è¯•å¤±è´¥")
    else:
        print("âœ… æ­¥éª¤2æˆåŠŸ: LLMé›†æˆæµ‹è¯•æˆåŠŸ")
    
    # æ­¥éª¤3: æµ‹è¯•Markdownç”Ÿæˆ
    print("\n[æ­¥éª¤3] æµ‹è¯•Markdownç”Ÿæˆ")
    md_success = generate_test_markdown(products)
    if not md_success:
        print("âŒ æ­¥éª¤3å¤±è´¥: æ— æ³•ç”ŸæˆMarkdownæ–‡ä»¶")
    else:
        print("âœ… æ­¥éª¤3æˆåŠŸ: æˆåŠŸç”ŸæˆMarkdownæ–‡ä»¶")
    
    # æ€»ç»“
    print("\n=== æµ‹è¯•æ€»ç»“ ===")
    if products and (llm_success or not llm_success) and md_success:
        print("âœ… æµ‹è¯•é€šè¿‡: å·¥ä½œæµç¨‹åŸºæœ¬åŠŸèƒ½æ­£å¸¸")
    else:
        print("âŒ æµ‹è¯•å¤±è´¥: å·¥ä½œæµç¨‹å­˜åœ¨é—®é¢˜ï¼Œè¯·æ£€æŸ¥ä¸Šè¿°é”™è¯¯")

if __name__ == "__main__":
    main() 