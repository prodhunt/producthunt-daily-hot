#!/usr/bin/env python3
"""
å¼‚æ­¥ä¼˜åŒ–ç‰ˆæœ¬çš„Product Huntå†…å®¹ç”Ÿæˆå™¨
å¤§å¹…æå‡LLMè°ƒç”¨æ€§èƒ½
"""

import sys
import os
import json
import asyncio
import time

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ° sys.path
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

try:
    from dotenv import load_dotenv
    load_dotenv()
except ImportError:
    print("dotenv æ¨¡å—æœªå®‰è£…ï¼Œå°†ç›´æ¥ä½¿ç”¨ç¯å¢ƒå˜é‡")

from datetime import datetime, timedelta, timezone
from scripts.llm_provider import get_llm_provider
from scripts.image_selector import ProductHuntImageSelector
from scripts.async_product_processor import AsyncProductProcessor, create_optimized_products
from scripts.scripts_product_hunt_list_to_md import fetch_product_hunt_data, fetch_mock_data

async def async_generate_hugo_front_matter(products_data, date_str, llm_provider):
    """å¼‚æ­¥ç”ŸæˆHugo Front Matter"""
    try:
        # åˆ›å»ºå¼‚æ­¥å¤„ç†å™¨
        processor = AsyncProductProcessor(llm_provider, max_concurrent=5)
        
        # å¼‚æ­¥ç”ŸæˆHugoæ ‡ç­¾
        print("ğŸ”„ æ­£åœ¨å¼‚æ­¥ç”ŸæˆHugoæ ‡ç­¾å’Œå…³é”®è¯...")
        tags_result = await processor.generate_hugo_tags(products_data)
        
        # è§£æJSONç»“æœ
        try:
            tags_data = json.loads(tags_result)
            tags = tags_data.get('tags', ['Product Hunt', 'æ¯æ—¥çƒ­æ¦œ', 'åˆ›æ–°äº§å“'])
            keywords = tags_data.get('keywords', ['Product Hunt', 'PHçƒ­æ¦œ', 'ä»Šæ—¥æ–°å“'])
        except json.JSONDecodeError:
            print("âš ï¸ æ ‡ç­¾ç”Ÿæˆç»“æœè§£æå¤±è´¥ï¼Œä½¿ç”¨é»˜è®¤æ ‡ç­¾")
            tags = ['Product Hunt', 'æ¯æ—¥çƒ­æ¦œ', 'åˆ›æ–°äº§å“']
            keywords = ['Product Hunt', 'PHçƒ­æ¦œ', 'ä»Šæ—¥æ–°å“', 'åˆ›æ–°äº§å“æ¨è', 'ç§‘æŠ€äº§å“']
        
        # é€‰æ‹©å°é¢å›¾ç‰‡
        image_selector = ProductHuntImageSelector()
        cover_url, alt_text = image_selector.select_best_cover_image(products_data)
        
        # è®¡ç®—æ€»ç¥¨æ•°
        total_votes = sum(p.get('votesCount', 0) for p in products_data)
        
        # ç”Ÿæˆæ ‡é¢˜å’Œæè¿°
        if products_data:
            top_product = products_data[0]
            title = f"Product Hunt ä»Šæ—¥çƒ­æ¦œ {date_str} | {top_product['name']}ç­‰{len(products_data)}æ¬¾åˆ›æ–°äº§å“"
            second_name = products_data[1]['name'] if len(products_data) > 1 else ''
            description = f"ä»Šæ—¥Product Huntçƒ­æ¦œç²¾é€‰ï¼š{top_product['name']}ã€{second_name}ç­‰{len(products_data)}æ¬¾åˆ›æ–°äº§å“ï¼Œæ€»ç¥¨æ•°{total_votes}ç¥¨"
        else:
            title = f"Product Hunt ä»Šæ—¥çƒ­æ¦œ {date_str}"
            description = f"ä»Šæ—¥Product Huntçƒ­æ¦œç²¾é€‰åˆ›æ–°äº§å“æ¨è"
        
        # æ„å»ºFront Matter
        front_matter = "---\n"
        front_matter += f'title: "{title}"\n'
        front_matter += f'date: {date_str}\n'
        front_matter += f'description: "{description}"\n'
        front_matter += f'tags: {json.dumps(tags, ensure_ascii=False)}\n'
        front_matter += f'keywords: {json.dumps(keywords, ensure_ascii=False)}\n'
        front_matter += f'votes: {total_votes}\n'
        if cover_url:
            front_matter += 'cover:\n'
            front_matter += f'  image: "{cover_url}"\n'
            front_matter += f'  alt: "{alt_text}"\n'
        front_matter += "---\n\n"
        
        print("âœ… Hugo Front Matterç”ŸæˆæˆåŠŸ")
        return front_matter
        
    except Exception as e:
        print(f"âš ï¸ Hugo Front Matterç”Ÿæˆå¤±è´¥: {e}")
        # è¿”å›åŸºç¡€çš„Front Matter
        total_votes = sum(p.get('votesCount', 0) for p in products_data)
        return f"""---
title: "Product Hunt ä»Šæ—¥çƒ­æ¦œ {date_str}"
date: {date_str}
description: "ä»Šæ—¥Product Huntçƒ­æ¦œç²¾é€‰åˆ›æ–°äº§å“æ¨è"
tags: ["Product Hunt", "æ¯æ—¥çƒ­æ¦œ", "åˆ›æ–°äº§å“"]
keywords: ["Product Hunt", "PHçƒ­æ¦œ", "ä»Šæ—¥æ–°å“", "åˆ›æ–°äº§å“æ¨è", "ç§‘æŠ€äº§å“"]
votes: {total_votes}
---

"""

async def async_generate_markdown(products_data, date_str):
    """å¼‚æ­¥ç”ŸæˆMarkdownå†…å®¹"""
    start_time = time.time()
    
    # è·å–LLMæä¾›å•†
    llm = get_llm_provider()
    
    # åˆ›å»ºå¼‚æ­¥å¤„ç†å™¨
    processor = AsyncProductProcessor(llm, max_concurrent=5)
    
    print(f"ğŸš€ å¼€å§‹å¼‚æ­¥å¤„ç† {len(products_data)} ä¸ªäº§å“...")
    
    # å¹¶å‘æ‰§è¡Œäº§å“å¤„ç†å’ŒHugo Front Matterç”Ÿæˆ
    products_task = processor.process_all_products(products_data)
    front_matter_task = async_generate_hugo_front_matter(products_data, date_str, llm)
    
    # ç­‰å¾…ä¸¤ä¸ªä»»åŠ¡å®Œæˆ
    async_results, front_matter = await asyncio.gather(products_task, front_matter_task)
    
    # åˆ›å»ºä¼˜åŒ–çš„äº§å“å¯¹è±¡
    optimized_products = create_optimized_products(products_data, async_results)
    
    # ç”ŸæˆMarkdownå†…å®¹
    markdown_content = front_matter
    markdown_content += f"# PHä»Šæ—¥çƒ­æ¦œ | {date_str}\n\n"
    
    for rank, product in enumerate(optimized_products, 1):
        markdown_content += product.to_markdown(rank)
    
    # ä¿å­˜æ–‡ä»¶
    os.makedirs('data', exist_ok=True)
    file_name = f"data/producthunt-daily-{date_str}.md"
    with open(file_name, 'w', encoding='utf-8') as file:
        file.write(markdown_content)
    
    end_time = time.time()
    total_time = end_time - start_time
    
    print(f"âœ… æ–‡ä»¶ {file_name} ç”ŸæˆæˆåŠŸï¼")
    print(f"â±ï¸ æ€»è€—æ—¶: {total_time:.1f}ç§’")
    
    # ä¼°ç®—æ€§èƒ½æå‡
    estimated_sync_time = len(products_data) * 9 + 10  # æ¯ä¸ªäº§å“9ç§’ + Hugoç”Ÿæˆ10ç§’
    time_saved = estimated_sync_time - total_time
    print(f"ğŸš€ ç›¸æ¯”åŒæ­¥ç‰ˆæœ¬èŠ‚çœ: {time_saved:.1f}ç§’")

def convert_products_to_data(products):
    """å°†Productå¯¹è±¡è½¬æ¢ä¸ºæ•°æ®å­—å…¸"""
    products_data = []
    for product in products:
        product_data = {
            'id': getattr(product, 'id', '1'),
            'name': product.name,
            'tagline': product.tagline,
            'description': product.description,
            'votesCount': product.votes_count,
            'createdAt': '2025-06-14T16:01:00Z',  # ä½¿ç”¨å›ºå®šæ—¶é—´
            'featuredAt': '2025-06-14T16:01:00Z' if product.featured == "æ˜¯" else None,
            'website': product.website,
            'url': product.url,
            'media': [{'url': product.og_image_url, 'type': 'image'}] if product.og_image_url else []
        }
        products_data.append(product_data)
    return products_data

async def main():
    """ä¸»å‡½æ•°"""
    yesterday = datetime.now(timezone.utc) - timedelta(days=1)
    date_str = yesterday.strftime('%Y-%m-%d')
    
    print("ğŸ”„ è·å–Product Huntæ•°æ®...")
    
    try:
        # è·å–çœŸå®æ•°æ®
        products = fetch_product_hunt_data()
        print(f"âœ… æˆåŠŸè·å– {len(products)} ä¸ªäº§å“")
    except Exception as e:
        print(f"âŒ è·å–Product Huntæ•°æ®å¤±è´¥: {e}")
        print("ğŸ”„ ä½¿ç”¨æ¨¡æ‹Ÿæ•°æ®ç»§ç»­...")
        products = fetch_mock_data()
    
    # è½¬æ¢ä¸ºæ•°æ®æ ¼å¼
    products_data = convert_products_to_data(products)
    
    # å¼‚æ­¥ç”ŸæˆMarkdown
    await async_generate_markdown(products_data, date_str)

def run_sync():
    """åŒæ­¥è¿è¡Œå…¥å£ï¼ˆç”¨äºå…¼å®¹æ€§ï¼‰"""
    asyncio.run(main())

if __name__ == "__main__":
    # æ£€æŸ¥æ˜¯å¦åœ¨å¼‚æ­¥ç¯å¢ƒä¸­
    try:
        # å¦‚æœå·²ç»åœ¨äº‹ä»¶å¾ªç¯ä¸­ï¼Œä½¿ç”¨create_task
        loop = asyncio.get_running_loop()
        print("æ£€æµ‹åˆ°ç°æœ‰äº‹ä»¶å¾ªç¯ï¼Œåˆ›å»ºä»»åŠ¡...")
        task = loop.create_task(main())
    except RuntimeError:
        # æ²¡æœ‰äº‹ä»¶å¾ªç¯ï¼Œåˆ›å»ºæ–°çš„
        print("ğŸš€ å¯åŠ¨å¼‚æ­¥Product Huntå†…å®¹ç”Ÿæˆå™¨...")
        asyncio.run(main())
